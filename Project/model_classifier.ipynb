{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset, Subset, SubsetRandomSampler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# roc_curve and average precision score requires the predicted probability instead of predicted label as input\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, average_precision_score, recall_score, f1_score, precision_score\n",
    "\n",
    "from PIL import Image\n",
    "import tqdm.notebook as tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inpiration for the classifier\n",
    "https://machinelearningmastery.com/building-a-binary-classification-model-in-pytorch/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class Linear_NN(torch.nn.Module):\n",
    "\n",
    "    # 180 is given from the one-hot encoding of the 20 amino acids * 9 peptide length\n",
    "    def __init__(self, input_size):\n",
    "        super(Linear_NN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, input_size // 2)\n",
    "        self.fc2 = torch.nn.Linear(input_size//2, input_size // 10)\n",
    "        self.fc3 = torch.nn.Linear(input_size//10, 1) \n",
    "        self.drop = torch.nn.Dropout(p=0.5)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = torch.nn.functional.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        out = self.fc3(x)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # Define the RNN layer\n",
    "        # Batch first means that the input and output tensors are provided as (batch, seq, feature)\n",
    "        # num_layers is the number of stacked RNN layers\n",
    "        self.rnn = torch.nn.RNN(input_size, hidden_size = 64, num_layers = 2, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Define the fully connected layer\n",
    "        self.fc = torch.nn.Linear(64, 1)\n",
    "\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        h0 = torch.zeros(2, x.size(0), 64).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Output shape = (batch_size, seq_length, hidden_size)\n",
    "        # -1 means the last element of the sequence\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptide_score_file = './data/HLA_B_4002.txt'\n",
    "\n",
    "def load_peptide_data(infile):\n",
    "\n",
    "    peptides = list()\n",
    "    labels = list()\n",
    "\n",
    "    with open(infile) as f:\n",
    "        for line in f:\n",
    "            peptide, score = line.strip().split()\n",
    "            peptides.append(list(peptide))\n",
    "            labels.append(float(score))\n",
    "\n",
    "    return peptides, labels\n",
    "\n",
    "peptides, labels = load_peptide_data(peptide_score_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_peptides(peptides, flatten = True):\n",
    "\n",
    "    flattened_peptides = np.array(peptides).flatten().reshape(-1, 1)\n",
    "\n",
    "    # Initialize the OneHotEncoder\n",
    "    encoder = OneHotEncoder(categories=[list('ACDEFGHIKLMNPQRSTVWY')], sparse_output=False)\n",
    "\n",
    "    # Transform the peptide sequences into a one-hot encoded format\n",
    "    one_hot_encoded = encoder.fit_transform(flattened_peptides)\n",
    "\n",
    "    \n",
    "    num_peptides = len(peptides)\n",
    "    \n",
    "    if flatten:\n",
    "        # Reshape back into the original peptide sequence format\n",
    "        one_hot_encoded = one_hot_encoded.reshape(num_peptides, -1)\n",
    "        \n",
    "        return one_hot_encoded\n",
    "\n",
    "    one_hot_encoded = one_hot_encoded.reshape(num_peptides, len(peptides[0]), -1)\n",
    "\n",
    "    return one_hot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA-reduced Pixel encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acid_full_names = {\n",
    "    'A': 'alanine', 'R': 'arginine', 'N': 'asparagine', 'D': 'aspartic_acid', 'C': 'cysteine', \n",
    "    'E': 'glutamic_acid', 'Q': 'glutamine', 'G': 'glycine', 'H': 'histidine', 'I': 'isoleucine', \n",
    "    'L': 'leucine', 'K': 'lysine', 'M': 'methionine', 'F': 'phenylalanine', 'P': 'proline',\n",
    "    'S': 'serine', 'T': 'threonine', 'W': 'tryptophan', 'Y': 'tyrosine', 'V': 'valine'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load amino acid depictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store images in cache to save performance\n",
    "image_cache = {}\n",
    "\n",
    "def load_AA_image(img_path, vgg = True):\n",
    "\n",
    "    if img_path in image_cache:\n",
    "        return image_cache[img_path]\n",
    "    \n",
    "    # Define transformation to do on image\n",
    "    \n",
    "    # Maybe not do it, if vgg is not the method\n",
    "    if vgg:\n",
    "        transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    image = Image.open(img_path).convert('RGB')\n",
    "    processed_image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    image_cache[img_path] = processed_image\n",
    "    \n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_pixel_features(amino_acid_full_names, reduce_dim = True):\n",
    "    \n",
    "    pixel_features = []\n",
    "\n",
    "    for letter, aa in amino_acid_full_names.items():\n",
    "        # load and preprocess\n",
    "        img_path = f'./2Dstruc/{aa}.png'\n",
    "        image = load_AA_image(img_path, vgg = False)\n",
    "        pixel_features.append(image.flatten())\n",
    "\n",
    "    pixel_features = np.vstack(pixel_features)\n",
    "\n",
    "    if reduce_dim:\n",
    "\n",
    "        # PCA\n",
    "        pca = PCA(random_state=42)\n",
    "        pixel_features = pca.fit_transform(pixel_features)\n",
    "\n",
    "        aa_features_dict = {}\n",
    "        for idx, aa in enumerate(amino_acid_full_names.keys()):\n",
    "            aa_features_dict[aa] = pixel_features[idx, :]\n",
    "\n",
    "        return aa_features_dict, pca\n",
    "    \n",
    "\n",
    "    # Create dictionary with aa_name:PCA_feature\n",
    "    aa_features_dict = {}\n",
    "    for idx, aa in enumerate(amino_acid_full_names.keys()):\n",
    "        aa_features_dict[aa] = pixel_features[idx, :]\n",
    "\n",
    "    return aa_features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot PCA Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PCA_variance(pca, encoding_method, cumulative=True):\n",
    "    # Assuming you have already performed PCA and stored it in the variable 'pca'\n",
    "    variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "    if cumulative:\n",
    "        cumulative_variance = np.cumsum(variance_ratio)\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, len(cumulative_variance)+1), cumulative_variance, '*-')\n",
    "        plt.xlabel('Number of Components')\n",
    "        plt.ylabel('Cumulative Variance')\n",
    "        plt.title('Cumulative Variance by Number of Components, Encoding Method: ' + encoding_method)\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure()\n",
    "        plt.bar(range(1, len(variance_ratio)+1), variance_ratio)\n",
    "        plt.xlabel('Number of Components')\n",
    "        plt.ylabel('Variance Ratio')\n",
    "        plt.title('Variance Ratio by Number of Components, Encoding Method: ' + encoding_method)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_features(amino_acid_full_names, reduce_dim = True):\n",
    "\n",
    "    # Define VGG model\n",
    "    vgg16_bn = torch.nn.Sequential(   \n",
    "    # Use only the convolutionary part\n",
    "    models.vgg16_bn(pretrained = True).features,\n",
    "    torch.nn.Flatten()\n",
    "    )\n",
    "\n",
    "    vgg16 = vgg16_bn.to(device)\n",
    "    vgg16.eval()\n",
    "\n",
    "    vgg_features = []\n",
    "\n",
    "    for aa in amino_acid_full_names.values():\n",
    "        # load and preprocess\n",
    "        img_path = f'./2Dstruc/{aa}.png'\n",
    "        image = load_AA_image(img_path)\n",
    "\n",
    "        # Disable gradient calculation\n",
    "        with torch.no_grad():\n",
    "            conv_features = vgg16(image)\n",
    "\n",
    "        vgg_features.append(conv_features.cpu().numpy())\n",
    "\n",
    "    vgg_features = np.vstack(vgg_features)\n",
    "\n",
    "    if reduce_dim:\n",
    "\n",
    "        pca = PCA(random_state=42)\n",
    "        vgg_features = pca.fit_transform(vgg_features)\n",
    "        \n",
    "        aa_features_dict = {}\n",
    "        for idx, aa in enumerate(amino_acid_full_names.keys()):\n",
    "            aa_features_dict[aa] = vgg_features[idx, :]\n",
    "\n",
    "        return aa_features_dict, pca\n",
    "\n",
    "    # Create dictionary with aa_name:PCA_feature\n",
    "    aa_features_dict = {}\n",
    "    for idx, aa in enumerate(amino_acid_full_names.keys()):\n",
    "        aa_features_dict[aa] = vgg_features[idx, :]\n",
    "\n",
    "    return aa_features_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50_feature_extractor(amino_acid_full_names):\n",
    "    resnet50 = models.resnet50(pretrained=True)\n",
    "    feature_extractor = torch.nn.Sequential(*list(resnet50.children())[:-1]).to(device)\n",
    "\n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    resnet50_features = {}\n",
    "\n",
    "    for letter, aa in amino_acid_full_names.items():\n",
    "        # load and preprocess\n",
    "        img_path = f'./2Dstruc/{aa}.png'\n",
    "        image = load_AA_image(img_path)\n",
    "        with torch.no_grad():\n",
    "            feature = feature_extractor(image)\n",
    "            resnet50_features[letter] = feature.cpu().numpy().flatten()\n",
    "    \n",
    "    return resnet50_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peptide Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder(peptides, aa_features_dict, flatten = True):\n",
    "    \n",
    "    encoded_peptides = []\n",
    "\n",
    "    for peptide in peptides:\n",
    "        encoded_peptide = []\n",
    "    \n",
    "        for aa in peptide:\n",
    "            encoded_peptide.append(aa_features_dict[aa])\n",
    "        \n",
    "        if flatten:\n",
    "            encoded_peptide = np.array(encoded_peptide).flatten()\n",
    "        \n",
    "        encoded_peptides.append(encoded_peptide)\n",
    "\n",
    "    return np.array(encoded_peptides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Chuan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size to the network: 2048\n"
     ]
    }
   ],
   "source": [
    "encoding_method = 'resnet50' # onehot, pixel, vgg, resnet50\n",
    "network_type = 'rnn' # linear, rnn\n",
    "reduce_dim = False\n",
    "\n",
    "# If input need to be flattened\n",
    "if network_type == 'linear':\n",
    "    flatten = True\n",
    "else:\n",
    "    flatten = False\n",
    "\n",
    "\n",
    "# Encode method\n",
    "if encoding_method == 'onehot':\n",
    "    encoded_peptides = one_hot_encode_peptides(peptides, flatten=flatten)\n",
    "\n",
    "elif encoding_method == 'pixel':\n",
    "    if reduce_dim:\n",
    "        aa_feature_dict, pca = PCA_pixel_features(amino_acid_full_names, reduce_dim=reduce_dim)\n",
    "    else:\n",
    "        aa_feature_dict = PCA_pixel_features(amino_acid_full_names, reduce_dim=reduce_dim)\n",
    "    \n",
    "    encoded_peptides = Encoder(peptides, aa_feature_dict, flatten=flatten)\n",
    "\n",
    "elif encoding_method == 'vgg':\n",
    "    if reduce_dim:\n",
    "        aa_feature_dict, pca = vgg_features(amino_acid_full_names, reduce_dim=reduce_dim)\n",
    "    else:   \n",
    "        aa_feature_dict = vgg_features(amino_acid_full_names, reduce_dim=reduce_dim)\n",
    "    \n",
    "    encoded_peptides = Encoder(peptides, aa_feature_dict, flatten=flatten)\n",
    "\n",
    "elif encoding_method == 'resnet50':\n",
    "    aa_feature_dict = resnet50_feature_extractor(amino_acid_full_names)\n",
    "    encoded_peptides = Encoder(peptides, aa_feature_dict, flatten=flatten)\n",
    "\n",
    "# If PCA is applied\n",
    "if reduce_dim and encoding_method != 'onehot':\n",
    "    plot_PCA_variance(pca, encoding_method, cumulative=True)\n",
    "  \n",
    "if network_type == 'linear':\n",
    "    input_size = encoded_peptides[0].shape[0]\n",
    "else:\n",
    "    input_size = encoded_peptides[0].shape[1]\n",
    "\n",
    "print(f'Input size to the network: {input_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to reset weight\n",
    "Reset weight to prevent bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        print(f'reset weight of layer {m}')\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training using 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_tensor = torch.tensor(encoded_peptides, dtype=torch.float32).to(device)\n",
    "labels_tensor = torch.tensor(np.asarray(labels).reshape(-1,1), dtype=torch.float32).to(device)\n",
    "\n",
    "peptides_dataset = TensorDataset(peptides_tensor, labels_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train_loss, val_loss, val_acc, fold):\n",
    "    \n",
    "    fig, ax = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "    for i, ytitle in enumerate(['loss', ['log loss']]):\n",
    "        ax[i].plot(train_loss, label='train loss', linestyle='-.')\n",
    "        ax[i].plot(val_loss, label='val loss', linestyle='-.')\n",
    "        ax[i].set_xlabel('Epoch')\n",
    "        ax[i].set_ylabel(ytitle)\n",
    "        ax[i].legend()\n",
    "    ax[1].set_yscale('log')\n",
    "\n",
    "    ax[2].plot(val_acc, label='val acc',  linestyle='-.')\n",
    "    ax[2].set_xlabel('Epoch')\n",
    "    ax[2].set_ylabel('Accuracy')\n",
    "    ax[2].legend()\n",
    "\n",
    "    plt.savefig(f'./loss/{network_type}/{encoding_method}_loss_fold_{fold}.png')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, X_train, y_train, X_val, y_val, fold):\n",
    "\n",
    "    # loss function and optimizer\n",
    "    loss_fn = torch.nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    n_epochs = 100   # number of epochs to run\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True, leave = False) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch+1}\")\n",
    "            \n",
    "            for start in bar:\n",
    "\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                \n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        \n",
    "        train_loss.append(epoch_loss/len(batch_start))\n",
    "\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        epoch_val_loss = loss_fn(y_pred, y_val).item()\n",
    "        acc = accuracy_score(y_val.cpu().numpy(), y_pred.round().cpu().detach().numpy())\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        val_loss.append(epoch_val_loss)\n",
    "        val_acc.append(acc)\n",
    "    \n",
    "\n",
    "    torch.save(best_weights, f'./model/{network_type}/{encoding_method}_model_fold_{fold}.pt')\n",
    "    plot_loss(train_loss, val_loss, val_acc, fold)\n",
    "    \n",
    "\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_splits = 5\n",
    "\n",
    "# train-test split: Hold out the test set for final model evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(peptides_tensor, labels_tensor, train_size=0.7, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "cv_scores = []\n",
    "for fold, (train, test) in enumerate(kfold.split(X_train, y_train), 1):\n",
    "    # create model, train, and get accuracy\n",
    "    \n",
    "    if network_type == 'linear':\n",
    "        model = Linear_NN(input_size)\n",
    "    elif network_type == 'rnn':\n",
    "        model = RNN(input_size)\n",
    "\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test], fold)\n",
    "    print(f\"Accuracy {fold}: %.5f\" % acc)\n",
    "    \n",
    "    cv_scores.append(acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(y_true, y_pred, label=None):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensembl(X_test, y_test, n_splits):  \n",
    "    \n",
    "    perf_f = open(f'./evaluation_result/performance/{network_type}/{encoding_method}_performance.txt', 'w')\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score,\n",
    "        'average precision score': average_precision_score,\n",
    "        'recall score': recall_score,\n",
    "        'f1 score': f1_score\n",
    "    }\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Random', color = 'k')\n",
    "\n",
    "    ensembl_predictions = []\n",
    "    score_lists = {name: [] for name in metrics.keys()}\n",
    "\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        \n",
    "        if network_type == 'linear':\n",
    "            model = Linear_NN(input_size)\n",
    "        elif network_type == 'rnn':\n",
    "            model = RNN(input_size)\n",
    "\n",
    "        model.load_state_dict(torch.load(f'./model/{network_type}/{encoding_method}_model_fold_{i+1}.pt'))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_prob = model(X_test).cpu()\n",
    "            ensembl_predictions.append(y_pred_prob)\n",
    "        \n",
    "        # plot roc for each fold\n",
    "        plot_roc(y_test.cpu(), y_pred_prob, label=f'Fold {i+1}')\n",
    "\n",
    "        # scoring each fold using the metrics\n",
    "        thereshold = 0.5\n",
    "        y_pred = (y_pred_prob.numpy() > thereshold).astype(int)\n",
    "        for name, scoring in metrics.items():\n",
    "            score_lists[name].append(scoring(y_test.cpu(), y_pred))\n",
    "\n",
    "\n",
    "    avg_ensembl_predictions = torch.stack(ensembl_predictions).mean(dim=0)\n",
    "\n",
    "    # Print score for each fold\n",
    "    print(f\"{'-'*50}\\nCross Validation\\n{'-'*50}\\n\", file=perf_f)\n",
    "    for name, scores in score_lists.items():\n",
    "            mean_score = np.mean(scores)\n",
    "            std_score = np.std(scores)\n",
    "            print(f\"{name}\", file=perf_f)\n",
    "            print(f\"5-Fold Cross-Validation {name} scores: {np.round(scores, 3)}\", file=perf_f)\n",
    "            print(f\"Mean {name} score: {mean_score:.3f} +/- {std_score:.3f}\\n\", file=perf_f)\n",
    "    \n",
    "    # Plot roc for ensembl\n",
    "    plot_roc(y_test.cpu(), avg_ensembl_predictions.cpu(), label='Ensemble')\n",
    "    plt.title(\"Receiver Operating Characteristics\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(f'./evaluation_result/roc/{network_type}/{encoding_method}_roc.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Calculate metrics scores for ensembl\n",
    "    avg_ensembl_predictions = (avg_ensembl_predictions.round().numpy() > thereshold).astype(int)\n",
    "    print(f\"{'-'*50}\\nEnsembl\\n{'-'*50}\\n\", file=perf_f)\n",
    "    for name, scoring in metrics.items():\n",
    "        print(f\"{name}\", file=perf_f)\n",
    "        print(f\"Ensembl {name} score: {scoring(y_test.cpu(),avg_ensembl_predictions):.3f}\\n\", file=perf_f)\n",
    "\n",
    "    perf_f.close()\n",
    "\n",
    "    # Note\n",
    "    # Change name of  ensembl_predictions to predictions and avg_e_prediction to ensembl_predictions\n",
    "    ensembl_predictions = [predictions.round().numpy() for predictions in ensembl_predictions]\n",
    "\n",
    "\n",
    "    # Save the prediction results\n",
    "    pred_f = open(f'./evaluation_result/predictions/{network_type}/{encoding_method}_predictions.txt', 'w')\n",
    "    y_test = y_test.numpy()\n",
    "    print('ytest  fold_1  fold_2  fold_3  fold_4  fold_5  ensembl', file = pred_f)\n",
    "    for i in range(len(y_test)):\n",
    "        print(y_test[i], end = '\\t', file = pred_f)\n",
    "        \n",
    "        for j in range(len(ensembl_predictions)):\n",
    "            print(ensembl_predictions[j][i], end = '\\t', file = pred_f)\n",
    "        \n",
    "        print(avg_ensembl_predictions[i], file = pred_f)\n",
    "    pred_f.close()\n",
    "\n",
    "              \n",
    "evaluate_ensembl(X_test, y_test, n_splits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
